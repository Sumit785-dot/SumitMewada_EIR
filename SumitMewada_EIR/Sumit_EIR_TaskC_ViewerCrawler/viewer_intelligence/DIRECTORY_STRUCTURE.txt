YouTube Viewer Intelligence Crawler - Directory Structure
=========================================================

viewer_intelligence/
â”‚
â”œâ”€â”€ ğŸ“„ README.md                          Main documentation (comprehensive guide)
â”œâ”€â”€ ğŸ“„ QUICKSTART.md                      5-minute setup guide
â”œâ”€â”€ ğŸ“„ METHODOLOGY.md                     Detailed technical methodology
â”œâ”€â”€ ğŸ“„ PROJECT_SUMMARY.md                 Project overview and completion status
â”œâ”€â”€ ğŸ“„ LICENSE                            MIT License with data usage terms
â”œâ”€â”€ ğŸ“„ DIRECTORY_STRUCTURE.txt            This file
â”‚
â”œâ”€â”€ ğŸ“„ requirements.txt                   Python dependencies
â”œâ”€â”€ ğŸ“„ .env.example                       Environment variables template
â”œâ”€â”€ ğŸ“„ .gitignore                         Git ignore rules
â”‚
â”œâ”€â”€ ğŸ main.py                            Main pipeline orchestrator (START HERE)
â”œâ”€â”€ ğŸ setup.py                           Automated setup script
â”œâ”€â”€ ğŸ test_pipeline.py                   Comprehensive test suite
â”œâ”€â”€ ğŸ generate_sample_data.py            Sample data generator
â”œâ”€â”€ ğŸ“„ pipeline.log                       Runtime logs (generated)
â”‚
â”œâ”€â”€ ğŸ“ src/                               Source code modules
â”‚   â”œâ”€â”€ ğŸ __init__.py                    Package initialization
â”‚   â”œâ”€â”€ ğŸ data_collector.py             YouTube Data API + yt-dlp integration
â”‚   â”œâ”€â”€ ğŸ nlp_analyzer.py               Language detection, NER, geocoding
â”‚   â”œâ”€â”€ ğŸ intelligence_aggregator.py    Confidence scoring & aggregation
â”‚   â”œâ”€â”€ ğŸ visualizer.py                 Chart and map generation
â”‚   â””â”€â”€ ğŸ report_generator.py           PDF and PNG report creation
â”‚
â”œâ”€â”€ ğŸ“ data/                              Data storage (created on first run)
â”‚   â”œâ”€â”€ ğŸ“ raw/                           Raw collected data
â”‚   â”‚   â””â”€â”€ ğŸ“„ video_data.json           Raw YouTube data (generated)
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ processed/                     Analyzed data
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ comment_analyses.csv      Detailed NLP analysis results
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ distribution_cities.csv   City-level estimates
â”‚   â”‚   â””â”€â”€ ğŸ“„ distribution_countries.csv Country-level estimates
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“ cache/                         Cached API responses
â”‚       â””â”€â”€ ğŸ“„ video_data.json           Cached data (reusable)
â”‚
â””â”€â”€ ğŸ“ outputs/                           Final outputs (generated)
    â”œâ”€â”€ ğŸ“„ viewer_intelligence_report.pdf     â­ 1-page PDF summary
    â”œâ”€â”€ ğŸ“„ viewer_intelligence_summary.png    â­ 1-page PNG summary
    â”‚
    â””â”€â”€ ğŸ“ charts/                        Individual visualizations
        â”œâ”€â”€ ğŸ“Š top_cities_bar.png         Top 10 cities bar chart
        â”œâ”€â”€ ğŸ“Š top_countries_bar.png      Top 15 countries bar chart
        â”œâ”€â”€ ğŸ“Š language_distribution_pie.png  Language pie chart
        â”œâ”€â”€ ğŸ“Š signal_breakdown.png       Signal types breakdown
        â”œâ”€â”€ ğŸ—ºï¸  interactive_map.html      Interactive city map (Folium)
        â””â”€â”€ ğŸ—ºï¸  choropleth_map.html       Interactive country map (Plotly)


KEY FILES TO START WITH:
========================

1. ğŸ“„ QUICKSTART.md          â† Read this first (5 minutes)
2. ğŸ setup.py               â† Run this to install everything
3. ğŸ main.py                â† Run this to execute the pipeline
4. ğŸ“„ README.md              â† Full documentation and methodology


TYPICAL WORKFLOW:
=================

Step 1: Setup
-------------
$ python setup.py
  â†’ Installs dependencies
  â†’ Downloads spaCy model
  â†’ Creates .env file

Step 2: Configure (Optional)
-----------------------------
$ edit .env
  â†’ Add YouTube API key (or skip to use cached data)

Step 3: Run Pipeline
--------------------
$ python main.py
  â†’ Collects video data
  â†’ Analyzes comments
  â†’ Generates visualizations
  â†’ Creates reports

Step 4: View Results
--------------------
$ open outputs/viewer_intelligence_report.pdf
$ open outputs/viewer_intelligence_summary.png
$ open outputs/charts/interactive_map.html


TESTING:
========

Run comprehensive tests:
$ python test_pipeline.py

Generate sample data (no API needed):
$ python generate_sample_data.py


FILE SIZES (Approximate):
==========================

Source Code:           ~150 KB
Documentation:         ~200 KB
Dependencies:          ~500 MB (including spaCy model)
Sample Data:           ~500 KB
Generated Outputs:     ~5 MB (charts + reports)
Total Project Size:    ~505 MB


GENERATED FILES:
================

These files are created when you run the pipeline:

âœ“ data/raw/video_data.json              - Raw YouTube data
âœ“ data/processed/comment_analyses.csv   - NLP analysis results
âœ“ data/processed/distribution_cities.csv - City estimates
âœ“ data/processed/distribution_countries.csv - Country estimates
âœ“ data/cache/video_data.json            - Cached data (reusable)
âœ“ outputs/viewer_intelligence_report.pdf - Main PDF report
âœ“ outputs/viewer_intelligence_summary.png - Visual summary
âœ“ outputs/charts/*.png                   - Static charts
âœ“ outputs/charts/*.html                  - Interactive maps
âœ“ pipeline.log                           - Runtime logs


DEPENDENCIES:
=============

Core Libraries (15):
- google-api-python-client  â†’ YouTube API
- yt-dlp                    â†’ Video data extraction
- spacy                     â†’ Named Entity Recognition
- langdetect                â†’ Language detection
- geotext                   â†’ Geographic extraction
- geopy                     â†’ Geocoding
- pandas                    â†’ Data manipulation
- matplotlib/seaborn        â†’ Static visualizations
- plotly                    â†’ Interactive charts
- folium                    â†’ Interactive maps
- reportlab                 â†’ PDF generation
- Pillow                    â†’ Image processing
- python-dotenv             â†’ Environment management

See requirements.txt for complete list with versions.


CONFIGURATION:
==============

Environment Variables (.env):
- YOUTUBE_API_KEY           â†’ YouTube Data API v3 key (optional)
- MAX_COMMENTS              â†’ Maximum comments to collect (default: 1000)
- API_QUOTA_LIMIT           â†’ Daily API quota limit (default: 10000)

Pipeline Settings (main.py):
- VIDEO_URL                 â†’ Target YouTube video URL
- MAX_COMMENTS              â†’ Comment limit
- USE_CACHE                 â†’ Use cached data (True/False)


OUTPUTS EXPLAINED:
==================

1. viewer_intelligence_report.pdf
   - Professional 1-page summary
   - Video metadata
   - Top 5 cities table
   - Key findings
   - Methodology notes
   - Confidence levels

2. viewer_intelligence_summary.png
   - Visual dashboard
   - Top cities chart
   - Language distribution
   - Country breakdown

3. Charts (outputs/charts/)
   - top_cities_bar.png       â†’ Horizontal bar chart
   - top_countries_bar.png    â†’ Vertical bar chart
   - language_distribution_pie.png â†’ Pie chart
   - signal_breakdown.png     â†’ Signal types used
   - interactive_map.html     â†’ City markers on map
   - choropleth_map.html      â†’ Country heatmap

4. Data Files (data/processed/)
   - comment_analyses.csv     â†’ Full NLP analysis
   - distribution_cities.csv  â†’ City estimates with confidence
   - distribution_countries.csv â†’ Country estimates with confidence


TROUBLESHOOTING:
================

Issue: "No API key found"
â†’ Solution: Add key to .env or set USE_CACHE=True

Issue: "spaCy model not found"
â†’ Solution: python -m spacy download en_core_web_sm

Issue: "No comments collected"
â†’ Solution: Check API key or use sample data

Issue: "Geocoding rate limit"
â†’ Solution: Reduce MAX_COMMENTS or use cache

See README.md â†’ Troubleshooting section for more help.


SUPPORT:
========

ğŸ“š Documentation:  README.md, QUICKSTART.md, METHODOLOGY.md
ğŸ§ª Testing:        python test_pipeline.py
ğŸ“ Logs:           pipeline.log
ğŸ› Issues:         Check logs and test suite


VERSION INFORMATION:
====================

Project Version:   1.0.0
Python Required:   3.8+
Last Updated:      2024-01-15
License:           MIT (see LICENSE file)


CREDITS:
========

Built with:
- Python 3.8+
- YouTube Data API v3
- spaCy NLP
- OpenStreetMap Nominatim
- And 15+ open-source libraries

For research and educational purposes.
